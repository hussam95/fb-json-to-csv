{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Parsing Through `fbjson2table` Libarary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Input -- JSON file\n",
    "Intermediate output -- 1 or mroe csvs per JSON depending on level of nesting\n",
    "Final output -- 1 concatenated csv per JSON\n",
    "root -- Path of directory containing FB's JSON dump files\n",
    "\"\"\"\n",
    "\n",
    "import fbjson2table\n",
    "from tabulate import tabulate\n",
    "from fbjson2table.table_class import TempDFs\n",
    "from fbjson2table.func_lib import parse_fb_json\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "root = \"/home/nouman/fb-json2table/Data/facebook-100007711683137/\"\n",
    "folders = os.listdir(root)\n",
    "\n",
    "# Let's create a csv at each level of nesting for every JSON\n",
    "# Let's save all the csvs per JSON into a separate directory named after JSON\n",
    "for folder in folders:\n",
    "    directory = folder\n",
    "    path= os.path.join(root,directory)\n",
    "    file= os.listdir(path)\n",
    "    if (len(file)==1) and (file[0]==\"no-data.txt\"):\n",
    "        continue\n",
    "    elif (len(file)==1) and (file[0]==\"media\"):\n",
    "        continue\n",
    "    else:\n",
    "        counter = len(file)\n",
    "        for i in range(counter):\n",
    "            file_name= file[i]\n",
    "            file_name= file_name.split(\".\")[0] # to remove .json from the parsed dir names\n",
    "            os.makedirs('/home/nouman/fb-json2table/Data/parsed_'+file_name, exist_ok=True)\n",
    "        \n",
    "            json_content = parse_fb_json(root+directory+'/'+file[i])\n",
    "            temp_dfs = TempDFs(json_content)\n",
    "\n",
    "            for df, table_name in zip(temp_dfs.df_list, temp_dfs.table_name_list):\n",
    "                #print(table_name,':')\n",
    "                #print(tabulate(df, headers='keys', tablefmt='psql'), '\\n')  \n",
    "                df.to_csv('/home/nouman/fb-json2table/Data/parsed_'+file_name+'/'+table_name+'.csv')   \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's concatenate all csvs per JSON to a single csv\n",
    "\n",
    "root = \"/home/nouman/fb-json2table/Data/\"\n",
    "folders = os.listdir(root)\n",
    "folders\n",
    "all_data={}\n",
    "\n",
    "for folder in folders:\n",
    "    if folder == \"facebook-100007711683137\":\n",
    "        continue\n",
    "    else:\n",
    "        path=r\"/home/nouman/fb-json2table/Data/\"+folder\n",
    "        all_files= glob.glob(path+\"/*.csv\")\n",
    "        \n",
    "        li = []\n",
    "        \n",
    "        for filename in all_files:\n",
    "            df = pd.read_csv(filename, index_col=None, header=0)\n",
    "            li.append(df)\n",
    "\n",
    "        frame = pd.concat(li, axis=1, ignore_index=False)\n",
    "        all_data[folder]=frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input -- JSON file\n",
      "Intermediate output -- 1 or mroe csvs per JSON depending on level of nesting\n",
      "Final output -- 1 concatenated csv per JSON\n",
      "root -- Path of directory containing FB's JSON dump files\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's save single csv per JSON (with concatenated pre-script) in a directory called concatenated_csvs         \n",
    "os.makedirs(\"/home/nouman/fb-json2table/concatenated_csvs\", exist_ok=True)\n",
    "new_key=\"\"\n",
    "\n",
    "for key in all_data:\n",
    "    splitted=key.split(\"_\")\n",
    "    for index, word in enumerate(splitted):\n",
    "        if index==0:\n",
    "            new_key=\"concatenated_\"\n",
    "        else:\n",
    "            new_key+=word+'_'\n",
    "            \n",
    "    dic= all_data[key]\n",
    "    df= pd.DataFrame(dic)\n",
    "    df.to_csv(\"/home/nouman/fb-json2table/concatenated_csvs/\"+new_key+'csv')\n",
    "    \n",
    "print(__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Parsing Using `Recursive` Technqiue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input --The script uses recursion to parse FB's JSON dump.\n",
      "Output --The script spits out single csv per JSON.\n",
      "root --The directory's path containing all the folders coming from FB; dtype=string. \n",
      "output_loc --The path of desired location to store csvs; dtype=string.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"Input --The script uses recursion to parse FB's JSON dump.\n",
    "Output --The script spits out single csv per JSON.\n",
    "root --The directory's path containing all the folders coming from FB; dtype=string. \n",
    "output_loc --The path of desired location to store csvs; dtype=string.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "   \n",
    "#Input dir path containing all folders coming from FB\n",
    "root = \"/home/nouman/Desktop/fb_parse/facebook-100007711683137/\"\n",
    "folders = os.listdir(root)\n",
    "\n",
    "# Output dir that will contain csvs\n",
    "os.makedirs(\"/home/nouman/Desktop/fb_parse/\"+\"parsed_csvs\",exist_ok=True)\n",
    "\n",
    "# Let's recursively parse each JSON present in each folder \n",
    "for folder in folders:\n",
    "    directory = folder\n",
    "    path= os.path.join(root,directory)\n",
    "    file= os.listdir(path)\n",
    "    if (len(file)==1) and (file[0]==\"no-data.txt\"):\n",
    "        continue\n",
    "    elif (len(file)==1) and (file[0]==\"media\"):\n",
    "        continue\n",
    "    else:\n",
    "        counter = len(file)\n",
    "        for i in range(counter):\n",
    "            file_name= file[i]\n",
    "            csv_file_name= file_name.split(\".\")[0] # to remove .json from the parsed dir names\n",
    "            \n",
    "            with open(root+directory+'/'+file_name, \"r\") as read_file:\n",
    "\n",
    "                developer = json.load(read_file)\n",
    "\n",
    "            dic={}  \n",
    "            def parse_json_recursively(json_object):\n",
    "\n",
    "                if type(json_object) is dict:\n",
    "\n",
    "                    for index,key in enumerate(json_object):\n",
    "                        parse_json_recursively(json_object[key])\n",
    "\n",
    "                        if (type(json_object[key]) is not dict) and (type(json_object[key]) is not list):\n",
    "                            #if key=='timestamp':\n",
    "                                #continue\n",
    "                            if key not in dic:\n",
    "                                dic[key]=[]\n",
    "\n",
    "                            if index==0:\n",
    "                                dic[key].append(json_object[key])\n",
    "                            elif key in dic:\n",
    "                                dic[key].append(json_object[key])\n",
    "\n",
    "\n",
    "\n",
    "                elif type(json_object) is list:\n",
    "                    for item in json_object:\n",
    "                        parse_json_recursively(item)\n",
    "                #p. loc. exception list not having dic but a list\n",
    "            \n",
    "            parse_json_recursively(developer)\n",
    "\n",
    "            df=pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in dic.items() ]))\n",
    "            \n",
    "            #df=df[~(df.duplicated('timestamp'))].reset_index(drop=True)\n",
    "            #df.dropna(axis=1,thresh=20)\n",
    "            \n",
    "            output_loc= \"/home/nouman/Desktop/fb_parse/parsed_csvs/\"+file_name+'.csv'  \n",
    "            df.to_csv(output_loc)   \n",
    "            #print(df)\n",
    "\n",
    "\n",
    "print(__doc__)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
